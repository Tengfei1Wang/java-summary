### Elasticsearch


### Kafka
详解：http://www.cnblogs.com/likehua/p/3999538.html

1.为什么使用消息队列？
解耦，异步，削峰（避免大数据量造成系统宕机）

2.Zookeeper在kafka中作用
1.broker注册；2.topic注册；3.生产者负载均衡；4.消费者信息；5.消费者和分区关系；6.消费者负载均衡；7.消费者offset提交（high level api）
3. 多分区的设计的特点： 
 1.为了并发读写，加快读写速度； 
 2.是利用多分区的存储，利于数据的均衡； 
 3.是为了加快数据的恢复速率，一但某台机器挂了，整个集群只需要恢复一部分数据，可加快故障恢复的时间。

Kafka快速写：
1.以顺序追加的方式向各个分区中写入消息-消息顺序写入磁盘。
2.同时，KAFKA采用了MMAP(Memory Mapped Files，内存映射文件)技术-利用操作系统的页缓存来实现文件到物理内存的直接映射。完成映射之后对物理内存的操作在适当时候会被同步到硬盘上。
Kafka快速读：零拷贝-在Linux中，是通过sendfile系统调用来完成的。Java提供了访问这个系统调用的方法：FileChannel.transferTo API。
Kafka使用sendfile，只需要一次拷贝就行：允许操作系统将数据直接从页缓存发送到网络上。所以在这个优化的路径中，只有最后一步将数据拷贝到网卡缓存中是需要的。这种页缓存和sendfile组合，意味着KAFKA集群的消费者大多数都完全从缓存消费消息，而磁盘没有任何读取活动


▪ack典型的值： 
0： 表示Producer从来不等待来自broker的确认信息。这个选择提供了最小的时延但同时风险最大（因为当server宕机时，数据将会丢失）。 
1：表示获得Leader replica已经接收了数据的确认信息。这个选择时延较小同时确保了server确认接收成功。 
-1：Producer会获得所有同步replicas都收到数据的确认。同时时延最大，然而，这种方式并没有完全消除丢失消息的风险，因为同步replicas的数量可能是1。如果你想确保某些replicas接收到数据，那么你应该在Topic-level设置中选项min.insync.replicas设置一下。
仅设置 acks= -1 也不能保证数据不丢失,当ISR列表中只有Leader时,同样有可能造成数据丢失。要保证数据不丢除了设置acks=-1，还要保证ISR的大小大于等于2。
▪具体参数设置： 
request.required.acks:设置为-1 等待所有ISR列表中的Replica接收到消息后采算写成功。 
min.insync.replicas: 设置为>=2,保证ISR中至少两个Replica。 
.kafka支持Gzip/snappy等多种压缩方式

### Redis
介绍：高性能的key-value数据库。
Redis 与其他 key - value 缓存产品有以下三个特点：
Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 
Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
Redis支持数据的备份，即master-slave模式的数据备份。 
持久化方式RDB，AOF：
AOF会消耗一部分性能，但是可以提高缓存一致性
RDS 提高频繁写性能，不启用备份来换取性能（可以通过save命令做备份）

1.解决redis aof文件过大的问题 
执行BGREWRITEAOF命令对redis的AOF进行重写
redis-cli BGREWRITEAOF

AOF重写作用：
(1) 随着AOF文件越来越大，里面会有大部分是重复命令或者可以合并的命令（100次incr = set key 100）
(2) 重写的好处：减少AOF日志尺寸，减少内存占用，加快数据库恢复时间。
